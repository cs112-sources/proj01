name: Autograding Tests
on:
  push:
  workflow_dispatch:
  repository_dispatch:
permissions:
  checks: write
  actions: read
  contents: read
jobs:
  run-autograding-tests:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install build tools
        run: sudo apt-get update && sudo apt-get install -y build-essential

      - name: Prepare results file path
        if: always()
        run: |
          echo "RESULTS_FILE=$RUNNER_TEMP/autograde-results.b64" >> "$GITHUB_ENV"
          : > "$RUNNER_TEMP/autograde-results.b64"

      # --- Compile test (from original) ---
      - name: compile via make
        id: compile-make
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: compile
          setup-command: make
          command: test -f tester
          timeout: 4
          max-score: 0
      - name: Record result (compile)
        if: always()
        run: |
          [ -n "${{ steps.compile-make.outputs.result }}" ] && \
          echo "${{ steps.compile-make.outputs.result }}" >> "$RESULTS_FILE" || true

      # --- Step 1 ---
      - name: step1
        id: step1
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: step1
          command: "./tester step1"
          timeout: 10
          max-score: 1
      - name: Record result (step1)
        if: always()
        run: |
          [ -n "${{ steps.step1.outputs.result }}" ] && \
          echo "${{ steps.step1.outputs.result }}" >> "$RESULTS_FILE" || true

      # --- Step 2 ---
      - name: step2
        id: step2
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: step2
          command: "./tester step2"
          timeout: 10
          max-score: 1
      - name: Record result (step2)
        if: always()
        run: |
          [ -n "${{ steps.step2.outputs.result }}" ] && \
          echo "${{ steps.step2.outputs.result }}" >> "$RESULTS_FILE" || true

      # --- Step 3 ---
      - name: step3
        id: step3
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: step3
          command: "./tester step3"
          timeout: 10
          max-score: 1
      - name: Record result (step3)
        if: always()
        run: |
          [ -n "${{ steps.step3.outputs.result }}" ] && \
          echo "${{ steps.step3.outputs.result }}" >> "$RESULTS_FILE" || true

      # --- Step 4 ---
      - name: step4
        id: step4
        uses: classroom-resources/autograding-command-grader@v1
        with:
          test-name: step4
          command: "./tester step4"
          timeout: 10
          max-score: 1
      - name: Record result (step4)
        if: always()
        run: |
          [ -n "${{ steps.step4.outputs.result }}" ] && \
          echo "${{ steps.step4.outputs.result }}" >> "$RESULTS_FILE" || true

      # --- Final summary step ---
      - name: Summarize autograding results & decide pass/fail
        if: always()
        shell: bash
        run: |
          set -euo pipefail

          SUMMARY="$RUNNER_TEMP/autograde-summary.md"
          : > "$SUMMARY"

          decode() { echo "$1" | base64 -d; }
          one_line() { tr -d '\n' | tr -d '\r'; }

          # parse_blob <base64> -> "name|prettyStatus|score|max|message|rawStatus"
          parse_blob() {
            local blob="$1"
            local json onel test status raw score max message name
            json="$(decode "$blob" 2>/dev/null || true)"
            onel="$(echo "$json" | one_line)"
            # Actions emit a single test per blob
            test="$(echo "$onel" | sed -E 's/.*"tests":[[]\{([^]]*)\}[]].*/{\1}/')"

            name="$(   echo "$test" | sed -E 's/.*"name":"([^"]*)".*/\1/')" || true
            raw="$(    echo "$test" | sed -E 's/.*"status":"([^"]*)".*/\1/')" || true
            score="$(  echo "$test" | sed -E 's/.*"score":([0-9]+).*/\1/')"  || true
            max="$(    echo "$onel" | sed -E 's/.*"max_score":([0-9]+).*/\1/')" || true
            message="$(echo "$test" | sed -E 's/.*"message":"([^"]*)".*/\1/')" || true

            case "$raw" in
              pass) status="âœ… Pass" ;;
              fail) status="âŒ Fail" ;;
              *)    status="âš ï¸ Unknown" ;;
            esac

            # For compile test, show a student-friendly message
            if [ "$name" = "compile" ]; then
              if [ "$raw" = "pass" ]; then
                message="Compiled successfully."
              else
                # If message is empty, show a generic error
                if [ -z "$message" ]; then
                  message="Compilation failed."
                fi
              fi
            fi

            # keep the table intact
            message="${message//|/\\|}"

            echo "${name:-(unnamed)}|${status}|${score:-0}|${max:-0}|${message}|${raw:-unknown}"
          }

          # Prepare markdown table for summary and ASCII table for logs
          {
            echo "## Autograding results"
            echo
            echo "| Test | Status | Points | Message |"
            echo "|---|---:|---:|---|"
          } >> "$SUMMARY"

          # Print ASCII table header for logs
          ascii_border='+----------------+----------+--------+------------------------------------------+'
          printf "\n===================== AUTOGRADING RESULTS =====================\n"
          printf "$ascii_border\n"
          printf "| %-14s | %-8s | %-6s | %-40s |\n" "Test" "Status" "Points" "Message"
          printf "$ascii_border\n"

          tot_score=0
          tot_max=0
          any_fail=0

          if [ -f "$RESULTS_FILE" ]; then
            while IFS= read -r line || [ -n "$line" ]; do
              [ -z "$line" ] && continue
              parsed="$(parse_blob "$line")"
              IFS='|' read -r name status score max message raw <<<"$parsed"
              # Markdown for summary
              echo "| ${name} | ${status} | ${score}/${max} | ${message} |" >> "$SUMMARY"
              # ASCII for logs (truncate message for log width)
              short_msg="${message:0:40}"
              points_col="${score}/${max}"
              printf "| %-14s | %-8s | %-6s | %-40s |\n" "$name" "$status" "$points_col" "$short_msg"
              tot_score=$((tot_score + ${score:-0}))
              tot_max=$((tot_max + ${max:-0}))
              [ "${raw:-unknown}" = "fail" ] && any_fail=1
            done < "$RESULTS_FILE"
            printf "$ascii_border\n"
          else
            echo "_No results recorded (RESULTS_FILE not found)_" >> "$SUMMARY"
            printf "| %-76s |\n" "No results recorded (RESULTS_FILE not found)"
            printf "+---------------------------------------------------------------------------------+\n"
          fi

          {
            echo
            if [ "$tot_score" -eq "$tot_max" ] && [ "$tot_max" -gt 0 ]; then
              echo "ðŸŽ‰ **Score:** ${tot_score}/${tot_max}"
            else
              echo "ðŸ“Š **Score:** ${tot_score}/${tot_max}"
            fi
          } >> "$SUMMARY"

          # Print markdown summary to Job Summary
          echo
          echo "==============================================================="
          echo
          cat "$SUMMARY" >> "$GITHUB_STEP_SUMMARY"

          # Fail here (single, clean failure)
          if [ "$any_fail" -ne 0 ]; then
            echo "::error::Autograding failed: one or more tests did not match the expected output. The full summary is shown above."
            exit 1
          fi
